# -*- coding: utf-8 -*-
"""Coding component for thesis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16qSywxLDEJ0gzz10H2xHExAYywTdE6zz

# Importing all the necessary libraries
"""

#import necessary libraries
import pandas as pd
import numpy as np
import random
import nltk
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from textblob import TextBlob
from nltk.sentiment import SentimentIntensityAnalyzer

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('vader_lexicon')

"""# Loading the data"""

amazon_reviews_dataset = pd.read_csv('reviews.csv', quotechar='"')
print(amazon_reviews_dataset.head())

# Count the occurrences of each score and ensure the order is from 1 to 5
counts = amazon_reviews_dataset['Score'].value_counts().sort_index()

# Create a bar plot
plt.bar(counts.index, counts.values, color='skyblue', edgecolor='black')

plt.xlabel('Score')
plt.ylabel('Amount of reviews under score')
plt.title('Score distribution')

plt.show()

"""# Pre-processing the data"""

# Initialize the lemmatizer
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    """
    Function to preprocess text by converting to lowercase, tokenizing,
    removing stopwords and punctuations, and lemmatizing.
    """
    # Convert text to lowercase
    text = str(text).lower()
    # Tokenize text
    tokens = word_tokenize(text)
    # Load stopwords only once to improve performance
    stop_words = set(stopwords.words('english'))
    # Remove stopwords and punctuations
    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]
    # Lemmatize words
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return " ".join(tokens)

def map_label(score):
    """
    Maps a numerical score to a category label.
    """
    if score <= 2:
        return 'negative'
    elif score == 3:
        return 'neutral'
    else:
        return 'positive'

# Apply preprocessing to the dataset
amazon_reviews_dataset['processed_text'] = amazon_reviews_dataset['Text'].apply(preprocess_text)

# Map scores to categories
amazon_reviews_dataset['true_category'] = amazon_reviews_dataset['Score'].apply(map_label)

# Count the occurrences of each category
category_counts = amazon_reviews_dataset['true_category'].value_counts()[['negative', 'neutral', 'positive']]

# Create a bar plot
plt.bar(category_counts.index, category_counts.values, color='skyblue', edgecolor='black')

plt.xlabel('Reviews sentiment')
plt.ylabel('Amount of reviews under score')
plt.title('Sentiment distribution')
plt.show()

"""# Performing sentiment analysis with lexicon-based algorithms"""

# Function to return the polarity score using TextBlob
def get_textblob_sentiment(text):
    return TextBlob(text).sentiment.polarity

# Initialize SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()

# Function to return the compound score using VADER
def get_vader_sentiment(text):
    return sia.polarity_scores(text)['compound']

# Function to apply sentiment analysis to a DataFrame
def apply_sentiment_analysis(df):
    df['TextBlob_Sentiment'] = df['processed_text'].apply(get_textblob_sentiment)
    df['VADER_Sentiment'] = df['processed_text'].apply(get_vader_sentiment)
    return df

# Classify TextBlob scores into categories
def classify_textblob(score):
    if score <= -0.1:
        return 'negative'
    elif score <= 0.1:
        return 'neutral'
    else:
        return 'positive'

# Classify VADER scores into categories
def classify_vader(score):
    if score <= -0.05:
        return 'negative'
    elif score <= 0.05:
        return 'neutral'
    else:
        return 'positive'

# Apply sentiment analysis and categorization
amazon_reviews_sentiment = apply_sentiment_analysis(amazon_reviews_dataset)
amazon_reviews_sentiment['TextBlob_category'] = amazon_reviews_sentiment['TextBlob_Sentiment'].apply(classify_textblob)
amazon_reviews_sentiment['VADER_category'] = amazon_reviews_sentiment['VADER_Sentiment'].apply(classify_vader)

# Set random seed for reproducibility
np.random.seed(42)
random.seed(42)

# Evaluation metrics
def calculate_accuracy_and_report(df, true_col, pred_col, model_name):
    accuracy = accuracy_score(df[true_col], df[pred_col])
    report = classification_report(df[true_col], df[pred_col], target_names=['negative', 'neutral', 'positive'])
    print(f"Accuracy for {model_name}: {accuracy}")
    print(f"\nClassification Report for {model_name}:\n{report}")

calculate_accuracy_and_report(amazon_reviews_sentiment, 'true_category', 'TextBlob_category', 'TextBlob')
calculate_accuracy_and_report(amazon_reviews_sentiment, 'true_category', 'VADER_category', 'VADER')

# Function to plot confusion matrix
def plot_confusion_matrix(df, true_col, pred_col, model_name):
    cm = confusion_matrix(df[true_col], df[pred_col])
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', xticklabels=['negative', 'neutral', 'positive'], yticklabels=['negative', 'neutral', 'positive'])
    plt.title(f'Confusion Matrix for {model_name}')
    plt.ylabel('Actual Labels')
    plt.xlabel('Predicted Labels')
    plt.show()

# Plotting confusion matrices
plot_confusion_matrix(amazon_reviews_sentiment, 'true_category', 'TextBlob_category', 'TextBlob')
plot_confusion_matrix(amazon_reviews_sentiment, 'true_category', 'VADER_category', 'VADER')

"""# Performing sentiment analysis with machine learning algorithms"""

# Set random seeds for reproducibility
np.random.seed(42)
random.seed(42)

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    amazon_reviews_dataset['processed_text'],
    amazon_reviews_dataset['true_category'],
    test_size=0.2,
    random_state=42
)

# Vectorize the text data
vectorizer = CountVectorizer()
X_train_vect = vectorizer.fit_transform(X_train)
X_test_vect = vectorizer.transform(X_test)

# Define parameter grids for GridSearchCV
nb_params = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}
rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [10, 50, 100, None]}

# Initialize GridSearchCV for Naive Bayes and Random Forest with 'f1_weighted' scoring
nb_grid = GridSearchCV(MultinomialNB(), nb_params, cv=5, scoring='f1_weighted')
rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5, scoring='f1_weighted')

# Fit models
nb_grid.fit(X_train_vect, y_train)
rf_grid.fit(X_train_vect, y_train)

# Predict using the best models
nb_predictions = nb_grid.best_estimator_.predict(X_test_vect)
rf_predictions = rf_grid.best_estimator_.predict(X_test_vect)

# Evaluation metrics
def calculate_accuracy_and_report(y_true, y_pred, model_name):
    print(f"Classification Report for {model_name}:")
    print(classification_report(y_true, y_pred, target_names=['negative', 'neutral', 'positive']))
    print(f"Confusion Matrix for {model_name}:")
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', cbar=False)
    plt.title(f'{model_name} Confusion Matrix')
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show()

# Generate reports for both models
calculate_accuracy_and_report(y_test, nb_predictions, 'Naive Bayes')
calculate_accuracy_and_report(y_test, rf_predictions, 'Random Forest')

#display the best parameters
print(nb_grid.best_estimator_)
print(rf_grid.best_estimator_)
